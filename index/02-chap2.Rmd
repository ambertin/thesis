# `fertile`: My Contribution To Addressing Reproducibility {#my-solution}

## Understanding The Gaps In Existing Reproducibility Solutions

Although the current state of reproducibility in academia is quite poor, it is not an impossible challenge to overcome. The relative simplicity of addressing reproducibility, particularly when compared with replicability, makes it an ideal candidate for solution-building. Although significant progress on addressing reproducibility on a widespread scale is a long-term challenge, impactful forward progress--if on a smaller scale--can be achieved in the short-term. 

As we have seen, software developers, data scientists, and educators around the world have realized this potential, taking steps to help address the current crisis of reproducibility. Journals have put in place guidelines for authors, statisticians have developed `R` packages that help structure projects in a reproducible format, and educators have begun integrate reproducibility exercises into their courses.

However, many of these attempts to address reproducibility have significant drawbacks associated with them. We have already explored the issues with journal policies, both for authors and reviewers, in-depth. In this section, we will consider the education and software solutions and their associated challenges.

### In Education

The two primary concerns about the integration of reproducibility in data science curricula revolve around time and difficulty.

As noted previously, the primary mode of teaching reproducibility is through the assignment of replication studies where students must take an existing study and go through the process of reproducing it themselves, including contacting the author for all necessary materials, rerunning code and analysis, and problem-solving when issues almost certainly come up. 

In addition to the time required for the professor to collect all of the studies that students will be working on, the inclusion of such an assignment places a significant burden on educators by taking up time where they could be teaching other important material. Replication studies, if done correctly, can take weeks for students to successfully complete. The choice to give such assignments is therefore associated with a significant opportunity cost which many professors are unwilling to take.

Additionally, both replication studies assigned in class and replication workshops outside of normal coursework require a working knowledge of how to successfully complete and understand research. This makes them inaccessible to individuals who are still in their undergraduate career and may not yet have had an opportunity to conduct research or those who are studying in non-research-focused technical programs.

In order to reach the widest variety of students possible, it is necessary to develop a new method of teaching reproducibility that is neither time consuming nor dependent on a prior understanding of the research process.

### In Software

Many of these packages are narrow, with each effectively addressing a small component of reproducibility: file structure, modularization of code, version control, etc. These packages often  succeed in their area of focus, but at the cost of accessibility to a wider audience. Their functions are often quite complex to use, and many steps must be completed to achieve the required reproducibility goal. This cumbersome nature means that most reproducibility packages currently available are not easily accessible to users near the beginning of their `R` journey, nor particularly useful to those looking for quick and easy reproducibility checks.

A more effective way of realizing widespread reproducibility is to make the process for doing so simple enough that it takes little to no conscious effort to implement. You want users to "fall into a hole" (we paraphrase Hadley Wickham) of good practice. 

However, while these tools can be useful, they are generalized so as to be useful to the widest audience. As a result, their checks are not designed to be `R`-specific, which makes them sub-optimal for users looking to address reproducibility issues involving features specific to the `R`  programming language, such as package installation and seed setting.


##  `fertile`, An R Package Creating Optimal Conditions For Reproducibility

### Package Overview

`fertile` attempts to address these gaps in existing software by providing a simple, easy-to-learn reproducibility package that, rather than focusing intensely on a specific area, provides some information about a wide variety of aspects influencing reproducibility. `fertile` is flexible, offering benefits to users at any stage in the data analysis workflow, and provides `R`-specific features, which address certain aspects of reproducibility that can be missed by external project development software.

`fertile` is designed to be used on data analyses organized as `R` Projects (i.e. directories containing an `.Rproj` file). Once an `R` Project is created, `fertile` provides benefits throughout the data analysis process, both during development as well as after the fact. `fertile` achieves this by operating in two modes: proactively (to prevent reproducibility mistakes from happening in the first place), and retroactively (analyzing code that has already been written for potential problems).

Much of the available literature focuses on file structure, organization, and naming, and `fertile`'s features are consistent with this. @marwick2018packaging provide the framework for file structure that `fertile` is based on: a structure similar to that of an `R` package (@coreteam-extensions, @hadley-packages), with an `R` folder, as well as `data`, `data-raw`, `inst`, and `vignettes`.


### Proactive Use

Proactively, the package identifies potential mistakes as they are made by the user and outputs an informative message as well as a recommended solution. For example, `fertile` catches when a user passes a potentially problematic file path---such as an absolute path, or a path that points to a location outside of the project directory---to a variety of common input/output functions operating on many different file types.

\footnotesize

```{r, echo = FALSE, message = FALSE}
library(stringr)
wrapoutput <- function(output, width = 80) {
 message(paste(strwrap(output, width = width), collapse = "\n"))
}
```

```{r write_csv, include=FALSE}
readr::write_csv(mtcars, "~/Desktop/my_data.csv")
```

```{r fertile, message = FALSE, error = TRUE}
library(fertile)
file.exists("~/Desktop/my_data.csv")
read.csv("~/Desktop/my_data.csv")
read.csv("../../../Desktop/my_data.csv")
```

\normalsize

`fertile` is even more aggressive with functions (like `setwd()`) that are almost certain to break reproducibility, causing them to throw errors that prevent their execution and providing recommendations for better alternatives.

\footnotesize

```{r setwd, message=FALSE, error = TRUE}
setwd("~/Desktop")
```

\normalsize

These proactive warning features are activated immediately after attaching the `fertile` package and require no additional effort by the user.

### Retroactive Use

Retroactively, `fertile` analyzes potential obstacles to reproducibility in an RStudio Project (i.e., a directory that contains an `.Rproj` file). The package considers several different aspects of the project which may influence reproducibility, including the directory structure, file paths, and whether randomness is used thoughtfully.

The end products of these analyses are reproducibility reports summarizing a project's adherence to reproducibility standards and recommending remedies for where the project falls short. For example, `fertile` might identify the use of randomness in code and recommend setting a seed if one is not present.

Users can access the majority of `fertile`'s retroactive features through two primary functions, `proj_check()` and `proj_analyze()`. 

The `proj_check()` function runs fifteen different reproducibility tests, noting which ones passed, which ones failed, the reason for failure, a recommended solution, and a guide to where to look for help. These tests include: looking for a clear build chain, checking to make sure the root level of the project is clear of clutter, confirming that there are no files present that are not being directly used by or created by the code, and looking for uses of randomness that do not have a call to `set.seed()` present. A full list is provided below:

\footnotesize

```{r list-checks, tidy.opts=list(width.cutoff=60)}
list_checks()
```

\normalsize

Subsets of the fifteen tests can be invoked using the `tidyselect` helper functions (@R-tidyselect) in combination with the more limited `proj_check_some()` function.

\footnotesize

```{r set-project}
proj_dir <- "project_miceps"
```

```{r echo=FALSE}
bad_file <- fs::path(proj_dir, "install_proj_packages.R")
if (file.exists(bad_file)) {
  fs::file_delete(bad_file)
}

```

```{r proj_check_some, warning = FALSE, tidy.opts=list(width.cutoff=60)}
proj_check_some(proj_dir, contains("paths"))
```

\normalsize

Each test can also be run individually by calling the function matching its check name.

The `proj_analyze()` function creates a report documenting the structure of a data analysis project. This report contains information about all packages referenced in code, the files present in the directory and their types, suggestions for moving files to create a more organized structure, and a list of reproducibility-breaking file paths used in code.

\footnotesize

```{r proj_analyze, tidy.opts=list(width.cutoff=60)}
proj_analyze(proj_dir)
```

\normalsize

### Logging

`fertile` also contains logging functionality, which records commands run in the console that have the potential to affect reproducibility, enabling users to look at their past history at any time. The package focuses mostly on package loading and file opening, noting which function was used, the path or package it referenced, and the timestamp at which that event happened. Users can access the log recording their commands at any time via the `log_report()` function:

\footnotesize

```{r read-csv, message=FALSE, include=FALSE}
library(purrr)
library(forcats)
read_csv(fs::path(proj_dir, "mice.csv"))
```

```{r log-report}
log_report()
```

\normalsize

The log, if not managed, can grow very long over time. For users who do not desire such functionality, `log_clear()` provides a way to erase the log and start over.

```{r log-clear, include=FALSE}
log_clear()
log_report()
```

### Utility Functions

`fertile` also provides several useful utility functions that may assist with the process of data analysis. 

### File Path Management

The `check_path()` function analyzes a vector of paths (or a single path) to determine whether there are any absolute paths or paths that lead outside the project directory.

\footnotesize

```{r path checks, error = TRUE, message = FALSE}
# Path inside the directory
check_path("project_miceps")

# Absolute path (current working directory)
check_path(getwd())

# Path outside the directory
check_path("../fertile.Rmd")
```

\normalsize


### File Types

There are several functions that can be used to check the type of a file: 

\footnotesize

```{r is_file}
is_data_file(fs::path(proj_dir, "mice.csv"))
is_image_file(fs::path(proj_dir, "proteins_v_time.png"))
is_text_file(fs::path(proj_dir, "README.md"))
is_r_file(fs::path(proj_dir, "analysis.Rmd"))
```

\normalsize

### Temporary Directories

The `sandbox()` function allows the user to make a copy of their project in a temporary directory. This can be useful for ensuring that projects run properly when access to the local file system is removed.

\footnotesize

```{r sandbox-1, results = 'hide'}
proj_dir
fs::dir_ls(proj_dir) %>% head(3)
```


```{r sandbox-2, echo = FALSE}
text <- fs::dir_ls(proj_dir) %>% head(3)
wrapoutput(str_wrap(text), 57)
```

```{r, sandbox-3, results = 'hide'}
temp_dir <- sandbox(proj_dir)
temp_dir
fs::dir_ls(temp_dir) %>% head(3)
```

```{r sandbox-4, echo = FALSE}
text <- fs::dir_ls(temp_dir) %>% head(3)
wrapoutput(str_wrap(text), 57)
```

\normalsize

### Managing Project Dependencies

One of the challenges with ensuring that work is reproducible is the issue of dependencies. Many data analysis projects reference a variety of `R` packages in their code. When such projects are shared with other users who may not have the required packages downloaded, it can cause errors that prevent the project from running properly. 

The `proj_pkg_script()`} function assists with this issue by making it simple and fast to download dependencies. When run on an `R` project directory, the function creates a `.R` script file that contains the code needed to install all of the packages referenced in the project, differentiating between packages located on CRAN and those located on GitHub.

\footnotesize

```{r proj_pkg_script, eval=TRUE, cache=TRUE, linewidth = 60}
install_script <- proj_pkg_script(proj_dir)
cat(readChar(install_script, 1e5))
```



\normalsize

## How `fertile` Works


Much of the functionality in `fertile` is achieved by writing `shims` **link to wikipedia page here**. `fertile`'s shimmed functions intercept the user's commands and perform various logging and checking tasks before executing the desired function. Our process is:

1. Identify an `R` function that is likely to be involved in operations that may break reproducibility. Popular functions associated with only one package (e.g., `read_csv()` from `readr`) are ideal candidates.

2. Create a function in `fertile` with the same name that takes the same arguments (and always the dots `...`).

3. Write this new function so that it: 
  a) captures any arguments, 
  b) logs the name of the function called, 
  c) performs any checks on these arguments, and 
  d) calls the original function with the original arguments. Except where warranted, the execution looks the same to the user as if they were calling the original function.
  
Most shims are quite simple and look something like what is shown below for `read_csv()`. 

\footnotesize

```{r}
fertile::read_csv
```

\normalsize

`fertile` shims many common functions, including those that read in a variety of data types, write data, and load packages. This works both proactively and retroactively, as the shimmed functions written in `fertile` are activated both when the user is coding interactively and when a file containing code is rendered.

In order to ensure that the `fertile` versions of functions ("shims") always supersede ("mask") their original namesakes when called, `fertile` uses its own shims of the `library` and `require` functions to  manipulate the `R` `search` path so that it is always located in the first position. In the `fertile` version of `library()`, we detach `fertile` from the search path, load the requested package, and then re-attach `fertile`. This ensures that when a user executes a command, `R` will check `fertile` for a matching function before considering other packages. While it is possible that this shifty behavior could lead to unintended consequences, our goal is to catch a good deal of problems before they become problematic. Users can easily disable `fertile` by detaching it, or not loading it in the first place. 


## `fertile` in Practice: Experimental Results From Smith College Student Use

`fertile` is designed to: 1) be simple enough that users with minimal `R` experience can use the package without issue, 2) increase the reproducibility of work produced by its users, and 3) educate its users on why their work is or is not reproducible and provide guidance on how to address any problems.

To test `fertile`'s effectiveness, we began an initial randomized control trial of the package on an introductory undergraduate data science course at Smith College in Spring 2020 **ADD FOOTNOTE** (This study was approved by Smith College IRB, Protocol #19-032).

The experiment was structured as follows:


1.Students are given a form at the start of the semester asking whether they consent to participate in a study on data science education. In order to successfully consent, they must provide their system username, collected through the command `Sys.getenv("LOGNAME")`. To maintain privacy the results are then transformed into a hexadecimal string via the `md5()` hashing function. 

2. These hexadecimal strings are then randomly assigned into equally sized groups, one experimental group that receives the features of `fertile` and one group that receives a control.

3. The students are then asked to download a package called `sds192` (the course number and prefix), which was created for the purpose of this trial. It leverages an `.onAttach()` function to scan the `R` environment and collect the username of the user who is loading the package and run it through the same hashing algorithm as used previously. It then identifies whether that user belongs to the experimental or the control group. Depending on the group they are in, they receive a different version of the package.

4. The experimental group receives the basic `sds192` package, which consists of some data sets and `R` Markdown templates necessary for completing homework assignments and projects in the class, but also has `fertile` installed and loaded silently in the background. The package's proactive features are enabled, and therefore users will receive warning messages when they use absolute or non-portable paths or attempt to change their working directory. The control group receives only the basic `sds192` package, including its data sets and `R` Markdown templates. All students from both groups then use their version of the package throughout the semester on a variety of projects.

5. Both groups are given a short quiz on different components of reproducibility that are intended to be taught by `fertile` at both the beginning and end of the semester. Their scores are then compared to see whether one group learned more than the other group or whether their scores were essentially equivalent. Additionally, for every homework assignment submitted, the professor takes note of whether or not the project compiles successfully.


Based on the results, we hope to determine whether `fertile` was successful at achieving its intended goals. A lack of notable difference between the *experimental* and *control* groups in terms of the number of code-related questions asked throughout the semester would indicate that `fertile` achieved its goal of simplicity. A higher average for the *experimental* group in terms of the number of homework assignments that compiled successfully would indicate that `fertile` was successful in increasing reproducibility. A greater increase over the semester in the reproducibility quiz scores for students in the *experimental* group compared with the *control* group would indicate that `fertile` achieved its goal of educating users on reproducibility. Success according to these metrics would provide evidence showing `fertile`'s benefit as tool to help educators introduce reproducibility concepts in the classroom.

